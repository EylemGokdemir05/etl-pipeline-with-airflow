version: '3.8'

services:
  postgres:
   image: postgres:15
   restart: unless-stopped
   environment:
    POSTGRES_USER: airflow
    POSTGRES_PASSWORD: airflow
    POSTGRES_DB: airflow
   volumes:
    - ./postgres-init:/docker-entrypoint-initdb.d:ro
    - postgres_data:/var/lib/postgresql/data
   healthcheck:
    test: ["CMD-SHELL", "pg_isready -U airflow"]
    interval: 10s
    timeout: 5s
    retries: 5
  airflow-webserver:
    image: apache/airflow:2.7.1
    restart: unless-stopped
    depends_on:
      postgres:
        condition: service_healthy
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      # AIRFLOW__CORE__FERNET_KEY: ''
      AIRFLOW__CORE__LOAD_EXAMPLES: "true"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./data:/opt/airflow/data  # Veri dosyalarını mount et (opsiyonel)
      - ./requirements.txt:/requirements.txt
      # - ./dbt:/opt/airflow/dbt    # dbt project'i mount et (opsiyonel)
      # - ./gcp/service-account.json:/opt/airflow/gcp-key.json:ro  # GCP servis hesabı anahtarını mount et (opsiyonel)
    ports:
      - "8080:8080"
    command: >
      bash -c "pip install --user -r /requirements.txt &&
               airflow db init &&
               airflow webserver"
  airflow-scheduler:
    image: apache/airflow:2.7.1
    depends_on:
      - airflow-webserver
      - postgres
    environment:
      AIRFLOW__CORE__EXECUTOR: LocalExecutor
      AIRFLOW__CORE__SQL_ALCHEMY_CONN: postgresql+psycopg2://airflow:airflow@postgres/airflow
      AIRFLOW__CORE__LOAD_EXAMPLES: "true"
    volumes:
      - ./airflow/dags:/opt/airflow/dags
      - ./airflow/logs:/opt/airflow/logs
      - ./airflow/plugins:/opt/airflow/plugins
      - ./requirements.txt:/requirements.txt
      - ./dbt:/opt/airflow/dbt
      - ./gcp:/opt/airflow/keys
      - ./data:/opt/airflow/data  # Veri dosyalarını mount et (opsiyonel)
    command: >
      bash -c "pip install --user -r /requirements.txt &&
               airflow db init &&
               airflow scheduler"
    restart: unless-stopped
  dbt:
    image: ghcr.io/dbt-labs/dbt-bigquery:1.7.latest
    volumes:
      - ./dbt:/app
      - ./gcp:/opt/airflow/keys
    environment:
      DBT_PROFILES_DIR: /app/profiles
    working_dir: /app
    entrypoint: [ "tail", "-f", "/dev/null" ]
volumes:
  postgres_data: